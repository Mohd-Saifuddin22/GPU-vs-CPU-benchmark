{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jQ9DoyPRZksw"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZFvyUTXWZ_B8",
        "outputId": "9a725a8d-2e30-4c72-ef0c-2eba1253022c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "batch_size = 4\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "# Increased num_workers for potentially faster data loading if CPU is powerful\n",
        "# and not bottle-necked by GPU. Adjust based on your system.\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
        "                                          shuffle=True, num_workers=4, pin_memory=True if device.type == 'cuda' else False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QZhsjJdLabLY",
        "outputId": "5aea2c18-868d-4ea1-ad8a-5e00a607dab9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:03<00:00, 42.9MB/s]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
        "                                         shuffle=False, num_workers=4, pin_memory=True if device.type == 'cuda' else False)\n",
        "\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f_U3nNJ9aqZ9",
        "outputId": "31183ed3-a158-45a4-c556-e78473d7cfc5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# functions to show an image\n",
        "def imshow(img):\n",
        "    img = img.cpu() # Move tensor to CPU for numpy conversion\n",
        "    img = img / 2 + 0.5     # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# get some random training images\n",
        "dataiter = iter(trainloader)\n",
        "images, labels = next(dataiter) # This will be on CPU by default from DataLoader\n",
        "\n",
        "# show images\n",
        "# To show images, they'd need to be moved to CPU if they were on GPU\n",
        "# For example: imshow(torchvision.utils.make_grid(images.cpu()))\n",
        "print (labels)\n",
        "print(' '.join(f'{classes[labels[j]]:5s}' for j in range(batch_size)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "loIHP75Ca6zq",
        "outputId": "4ecf0299-f2c8-4d11-eb42-2b2491848aa2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([4, 7, 1, 1])\n",
            "deer  horse car   car  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "net = Net()\n",
        "net.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ji50erpQbPhC",
        "outputId": "cfc8b7bd-545d-4e39-d869-5f74b1ccdba1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Net(\n",
              "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
              "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
              "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# Record start time\n",
        "start_time = time.time()\n",
        "\n",
        "print(\"Starting Training...\")\n",
        "for epoch in range(2):  # loop over the dataset multiple times\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        # ---- Move inputs and labels to the chosen device ----\n",
        "        inputs, labels = data[0].to(device), data[1].to(device)\n",
        "        # ----------------------------------------------------\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
        "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')\n",
        "\n",
        "# Record end time\n",
        "end_time = time.time()\n",
        "\n",
        "# Calculate and print training time\n",
        "training_time = end_time - start_time\n",
        "print(f'Training took: {training_time:.2f} seconds')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HVLUKB03bXCA",
        "outputId": "c1c82b3b-076a-4937-967b-985ea8c13e13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1,  2000] loss: 2.223\n",
            "[1,  4000] loss: 1.873\n",
            "[1,  6000] loss: 1.688\n",
            "[1,  8000] loss: 1.575\n",
            "[1, 10000] loss: 1.534\n",
            "[1, 12000] loss: 1.476\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2,  2000] loss: 1.434\n",
            "[2,  4000] loss: 1.379\n",
            "[2,  6000] loss: 1.349\n",
            "[2,  8000] loss: 1.329\n",
            "[2, 10000] loss: 1.292\n",
            "[2, 12000] loss: 1.316\n",
            "Finished Training\n",
            "Training took: 111.64 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "PATH = './cifar_net.pth'\n",
        "torch.save(net.state_dict(), PATH)"
      ],
      "metadata": {
        "id": "HendoUOMb3IX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Testing Part ---\n",
        "# We need a new instance of the network for loading the state dict,\n",
        "# and it also needs to be on the correct device.\n",
        "net_loaded = Net()\n",
        "net_loaded.to(device) # ---- Move the loaded model to the chosen device ----\n",
        "net_loaded.load_state_dict(torch.load(PATH)) # Load the state dictionary\n",
        "\n",
        "# Get some test images\n",
        "dataiter = iter(testloader)\n",
        "images_test, labels_test = next(dataiter)\n",
        "images_test, labels_test = images_test.to(device), labels_test.to(device) # Move test data to device\n",
        "\n",
        "# print images (optional, ensure imshow handles tensors on device or move to cpu)\n",
        "# imshow(torchvision.utils.make_grid(images_test.cpu()))\n",
        "# print('GroundTruth: ', ' '.join(f'{classes[labels_test[j]]:5s}' for j in range(batch_size)))\n",
        "\n",
        "\n",
        "outputs_test = net_loaded(images_test) # Use the loaded and device-mapped network\n",
        "\n",
        "_, predicted_test = torch.max(outputs_test, 1)\n",
        "\n",
        "# print('Predicted: ', ' '.join(f'{classes[predicted_test[j]]:5s}'\n",
        "#                               for j in range(batch_size)))"
      ],
      "metadata": {
        "id": "jlauYCMIcAJ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "# since we're not training, we don't need to calculate the gradients for our outputs\n",
        "with torch.no_grad(): # Disables gradient calculation\n",
        "    net_loaded.eval() # Set the model to evaluation mode\n",
        "    for data in testloader:\n",
        "        # ---- Move inputs and labels to the chosen device ----\n",
        "        images, labels = data[0].to(device), data[1].to(device)\n",
        "        # ----------------------------------------------------\n",
        "        # calculate outputs by running images through the network\n",
        "        outputs = net_loaded(images)\n",
        "        # the class with the highest energy is what we choose as prediction\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy of the network on the 10000 test images: {100 * correct // total} %')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1oet55gccG5s",
        "outputId": "2cf33e1e-0e3f-49b1-cf0d-20336074080f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on the 10000 test images: 53 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prepare to count predictions for each class\n",
        "correct_pred = {classname: 0 for classname in classes}\n",
        "total_pred = {classname: 0 for classname in classes}\n",
        "\n",
        "# again no gradients needed\n",
        "with torch.no_grad(): # Disables gradient calculation\n",
        "    net_loaded.eval() # Set the model to evaluation mode\n",
        "    for data in testloader:\n",
        "        # ---- Move inputs and labels to the chosen device ----\n",
        "        images, labels = data[0].to(device), data[1].to(device)\n",
        "        # ----------------------------------------------------\n",
        "        outputs = net_loaded(images)\n",
        "        _, predictions = torch.max(outputs, 1)\n",
        "        # collect the correct predictions for each class\n",
        "        for label, prediction in zip(labels, predictions):\n",
        "            # Ensure label and prediction are on CPU if classes is a CPU-based structure\n",
        "            # or if further operations on them expect CPU tensors/values\n",
        "            label_item = label.item()\n",
        "            prediction_item = prediction.item()\n",
        "            if label_item == prediction_item:\n",
        "                correct_pred[classes[label_item]] += 1\n",
        "            total_pred[classes[label_item]] += 1\n",
        "\n",
        "\n",
        "# print accuracy for each class\n",
        "for classname, correct_count in correct_pred.items():\n",
        "    accuracy = 100 * float(correct_count) / total_pred[classname]\n",
        "    print(f'Accuracy for class: {classname:5s} is {accuracy:.1f} %')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HKeukBq4cPKj",
        "outputId": "9ed9dbff-aff1-4054-a756-abd7b1d59a1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for class: plane is 50.1 %\n",
            "Accuracy for class: car   is 44.1 %\n",
            "Accuracy for class: bird  is 41.1 %\n",
            "Accuracy for class: cat   is 17.4 %\n",
            "Accuracy for class: deer  is 48.9 %\n",
            "Accuracy for class: dog   is 51.2 %\n",
            "Accuracy for class: frog  is 50.5 %\n",
            "Accuracy for class: horse is 73.4 %\n",
            "Accuracy for class: ship  is 78.0 %\n",
            "Accuracy for class: truck is 75.9 %\n"
          ]
        }
      ]
    }
  ]
}